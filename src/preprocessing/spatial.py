import numpy as np
from scipy.interpolate import interp2d
from scipy.ndimage import gaussian_filter
from sklearn.decomposition import PCA, IncrementalPCA
import xarray as xr
import numpy as np
import uuid
from pathlib import Path
from ..core.utilities import *
from ..core.progressbar import *
from .missing_values import *


def regrid(X, lons, lats, x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None, use_dask=True, feat_chunks=1, samp_chunks=1, kind='linear'):
    x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim = guess_coords(
        X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
    check_all(X, x_lat_dim, x_lon_dim,  x_sample_dim, x_feature_dim)
    same = True
    if len(X.coords[x_lat_dim].values) == len(lats):
        for i in range(len(X.coords[x_lat_dim].values)):
            if X.coords[x_lat_dim].values[i] != lats[i]:
                same = False
    else:
        same = False
    if len(X.coords[x_lon_dim].values) == len(lons):
        for i in range(len(X.coords[x_lon_dim].values)):
            if X.coords[x_lon_dim].values[i] != lons[i]:
                same = False
    else:
        same = False
    if same:
        return X

    X1 = fill_space_mean(X, x_lat_dim, x_lon_dim,  x_sample_dim, x_feature_dim)
    X1 = X1.chunk({x_feature_dim: max(X.shape[list(X.dims).index(x_feature_dim)] // feat_chunks, 1), x_sample_dim: max(
        X.shape[list(X.dims).index(x_sample_dim)] // samp_chunks, 1)}).transpose(x_feature_dim, x_sample_dim, x_lat_dim, x_lon_dim)

    hdf = None

    results, seldct = [], {}
    feature_ndx = 0
    for i in range(len(X1.chunks[list(X1.dims).index(x_feature_dim)])):
        sample_ndx = 0
        results.append([])
        for j in range(len(X1.chunks[list(X1.dims).index(x_sample_dim)])):
            x_isel = {x_feature_dim: slice(feature_ndx, feature_ndx + X1.chunks[list(X1.dims).index(
                x_feature_dim)][i]), x_sample_dim: slice(sample_ndx, sample_ndx + X1.chunks[list(X1.dims).index(x_sample_dim)][j])}
            results[i].append(regrid_chunk(X1.isel(**x_isel), lats, lons,  x_lat_dim, x_lon_dim,  x_sample_dim,
                              x_feature_dim, use_dask=use_dask, hdf=hdf, feature_ndx=feature_ndx, sample_ndx=sample_ndx, kind=kind))
            sample_ndx += X1.chunks[list(X1.dims).index(x_sample_dim)][j]
        feature_ndx += X1.chunks[list(X1.dims).index(x_feature_dim)][i]
        results[i] = np.concatenate(results[i], axis=1)
    results = np.concatenate(results, axis=0)

    X1 = X1.transpose(x_feature_dim, x_sample_dim, x_lat_dim, x_lon_dim)
    coords = {
        x_lat_dim: lats,
        x_lon_dim: lons,
        x_feature_dim: X1.coords[x_feature_dim].values,
        x_sample_dim: X1.coords[x_sample_dim].values
    }
    attrs = X1.attrs
    # attrs.update({'generated by': 'XCAST regrid')
    ret = xr.DataArray(data=results, coords=coords, dims=X1.dims, attrs=attrs)
    selection = {x_lat_dim: lats, x_lon_dim: lons}
    mask = X.sel(**selection, method='nearest') / \
        X.sel(**selection, method='nearest')
    mask.coords[x_lat_dim] = lats
    mask.coords[x_lon_dim] = lons
    r = ret
    r.attrs['generated_by'] = attrs['generated_by'] + \
        '\n  XCAST regridded' if 'generated_by' in attrs.keys() else '\n  XCAST regridded'
    return r


def regrid_chunk(X, lats, lons, x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None, use_dask=False, hdf=None, feature_ndx=0, sample_ndx=0, kind='linear'):
    res = []
    # X1 = fill_space_mean(X, x_lat_dim=x_lat_dim, x_lon_dim=x_lon_dim, x_sample_dim=x_sample_dim, x_feature_dim=x_feature_dim)
    data = X.values
    for i in range(data.shape[0]):
        res.append([])
        for j in range(data.shape[1]):
            interp_func = interp2d(
                X.coords[x_lon_dim].values, X.coords[x_lat_dim].values, data[i, j, :, :], kind=kind)
            interped = interp_func(lons, lats)
            res[i].append(interped)
    res = np.asarray(res)
    return res


class SpatialPCA:
    def __init__(self, **kwargs):
        self.kwargs = kwargs

    def fit(self, X, x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None, ):
        x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim = guess_coords(
            X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
        check_all(X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
        self.shape = shape(X, x_lat_dim=x_lat_dim, x_lon_dim=x_lon_dim,
                           x_sample_dim=x_sample_dim, x_feature_dim=x_feature_dim)
        self.transformers = []

        point = X.mean(x_feature_dim, skipna=False).stack(
            point=(x_lat_dim, x_lon_dim)).dropna('point')
        for i in range(self.shape[-1]):
            self.transformers.append(PCA(**self.kwargs))
            data = X.isel(**{x_feature_dim: i}).stack(point=(x_lat_dim, x_lon_dim)
                                                      ).sel(point=point.point).transpose(x_sample_dim, 'point').values
            self.transformers[i].fit(data)

        loadings = []
        for i in range(self.shape[-1]):
            loadings.append(self.transformers[i].components_)
        loadings = np.stack(loadings)
        modes = self.transformers[0].components_.shape[0]
        coords = {
            x_feature_dim: X.coords[x_feature_dim].values,
            'MODE': [i for i in range(modes)],
            'point': point.point
        }
        attrs = {'generated by': 'XCAST Spatial PCA EOFS'}
        self.loadings = xr.DataArray(name='spatial_loadings', data=loadings, coords=coords, dims=[
                                     x_feature_dim, 'MODE', 'point'], attrs=attrs).unstack('point').sortby(x_lat_dim).sortby(x_lon_dim)

    def transform(self, X, x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None, ):
        x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim = guess_coords(
            X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
        check_all(X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
        newshape = shape(X, x_lat_dim=x_lat_dim, x_lon_dim=x_lon_dim,
                         x_sample_dim=x_sample_dim, x_feature_dim=x_feature_dim)
        for i in range(4):
            assert newshape[i] == self.shape[i], 'incompatible shape with fit X'

        scores = []
        for i in range(self.shape[-1]):
            data = X.isel(**{x_feature_dim: i}).stack(point=(x_lat_dim, x_lon_dim)
                                                      ).dropna('point').transpose(x_sample_dim, 'point').values
            scores.append(self.transformers[i].transform(data))
        scores = np.stack(scores)
        modes = self.transformers[0].components_.shape[0]

        coords = {
            x_feature_dim: X.coords[x_feature_dim].values,
            'MODE': [i for i in range(modes)],
            x_sample_dim: X.coords[x_sample_dim].values
        }
        attrs = {'generated by': 'XCAST Spatial PCA EOFS'}
        return xr.ones_like(X) * xr.DataArray(name='spatial_loadings', data=scores, coords=coords, dims=[x_feature_dim, x_sample_dim, 'MODE'], attrs=attrs)


def gaussian_smooth(X, x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None, kernel=3, use_dask=False, feature_chunks=1, sample_chunks=1):
    x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim = guess_coords(
        X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
    check_all(X, x_lat_dim, x_lon_dim,  x_sample_dim, x_feature_dim)
    # X1 = fill_space_mean(X, x_lat_dim, x_lon_dim,  x_sample_dim, x_feature_dim )
    X1 = X.chunk({x_feature_dim: max(X.shape[list(X.dims).index(x_feature_dim)] // feature_chunks, 1), x_sample_dim: max(
        X.shape[list(X.dims).index(x_sample_dim)] // sample_chunks, 1)}).transpose(x_feature_dim, x_sample_dim, x_lat_dim, x_lon_dim)

    hdf = None

    results, seldct = [], {}
    feature_ndx = 0
    for i in range(len(X1.chunks[list(X1.dims).index(x_feature_dim)])):
        sample_ndx = 0
        results.append([])
        for j in range(len(X1.chunks[list(X1.dims).index(x_sample_dim)])):
            x_isel = {x_feature_dim: slice(feature_ndx, feature_ndx + X1.chunks[list(X1.dims).index(
                x_feature_dim)][i]), x_sample_dim: slice(sample_ndx, sample_ndx + X1.chunks[list(X1.dims).index(x_sample_dim)][j])}
            results[i].append(gaussian_smooth_chunk(X1.isel(**x_isel), feature_ndx, sample_ndx, x_lat_dim,
                              x_lon_dim,  x_sample_dim, x_feature_dim, use_dask=use_dask, kernel=kernel, hdf=hdf))
            sample_ndx += X1.chunks[list(X1.dims).index(x_sample_dim)][j]
        feature_ndx += X1.chunks[list(X1.dims).index(x_feature_dim)][i]
        results[i] = np.concatenate(results[i], axis=1)
    results = np.concatenate(results, axis=0)
    # X1 = X1.transpose(x_sample_dim, x_feature_dim, x_lat_dim, x_lon_dim)
    attrs = X1.attrs

    r = xr.DataArray(data=results, coords=X1.coords, dims=X1.dims, attrs=attrs)
    r.attrs['generated_by'] = attrs['generated_by'] + '\n  XCAST Gaussian Smoothing {}'.format(
        kernel) if 'generated_by' in attrs.keys() else '\n  XCAST Gaussian Smoothing {}'.format(kernel)
    return r

import copy
def gaussian_smooth_chunk(X, feature_ndx, sample_ndx, x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None, kernel=3, use_dask=False, hdf=None):
    assert isinstance(kernel, int), "Kernel must be an odd integer - tuples not accepted as of xcast 0.5.7"
    s = 2
    w = kernel
    t = (((w - 1)/2)-0.5)/s
    res = []
    data = X.values
    for i in range(data.shape[0]):
        res.append([])
        for j in range(data.shape[1]):
            toblur = data[i, j, :, :]
            mask = np.isnan(toblur)
            toblur2 = copy.deepcopy(toblur)
            toblur2[mask] = np.nanmean(toblur)
            blurred = gaussian_filter(toblur2, sigma=s, truncate=t)
            blurred[mask] = np.nan
            res[i].append(blurred)
    res = np.asarray(res)
    return res
